# src/models/train_model.py

import pandas as pd
import xgboost as xgb
import joblib
import os
import sys

# --- ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n ---
try:
    # L·∫•y ƒë∆∞·ªùng d·∫´n g·ªëc c·ªßa d·ª± √°n (ƒëi l√™n 2 c·∫•p)
    PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
except NameError:
    # X·ª≠ l√Ω n·∫øu ch·∫°y tr·ª±c ti·∫øp
    PROJECT_ROOT = os.path.abspath(os.path.join('.', '..', '..'))
    if not os.path.exists(os.path.join(PROJECT_ROOT, 'src', 'models')):
        PROJECT_ROOT = os.path.abspath('.') # Th·ª≠ gi·∫£ ƒë·ªãnh ƒëang ch·∫°y t·ª´ th∆∞ m·ª•c g·ªëc

PROCESSED_DATA_DIR = os.path.join(PROJECT_ROOT, "data", "03_processed")
MODELS_DIR = os.path.join(PROJECT_ROOT, "models") # Th∆∞ m·ª•c models c·∫•p g·ªëc

TRAIN_CLEAN_PATH = os.path.join(PROCESSED_DATA_DIR, "train_clean.csv")
MODEL_OUTPUT_PATH = os.path.join(MODELS_DIR, "xgboost_v1.pkl") # T√™n file m√¥ h√¨nh

# --- Si√™u tham s·ªë t·ªët nh·∫•t t·ª´ Optuna t·ª´ notebook ---
BEST_XGB_PARAMS = {
    'n_estimators': 795,
    'learning_rate': 0.041781133811210534,
    'max_depth': 4,
    'subsample': 0.9004238636768309,
    'colsample_bytree': 0.8861701514544139,
    'gamma': 0.0007839147453102702,
    'min_child_weight': 3,
    'random_state': 42
}

def train_model(train_data_path, model_output_path, params):
    """
    Hu·∫•n luy·ªán m√¥ h√¨nh XGBoost t·ªët nh·∫•t tr√™n to√†n b·ªô d·ªØ li·ªáu train s·∫°ch
    v√† l∆∞u m√¥ h√¨nh.
    """
    print("B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh...")

    # 1. T·∫£i d·ªØ li·ªáu train s·∫°ch
    print(f"ƒêang t·∫£i d·ªØ li·ªáu hu·∫•n luy·ªán t·ª´: {train_data_path}")
    try:
        df_train = pd.read_csv(train_data_path)
    except FileNotFoundError:
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {train_data_path}")
        print(f"   H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ ch·∫°y script x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")
        sys.exit(1)

    # 2. Chu·∫©n b·ªã X_train v√† y_train
    print("   Chu·∫©n b·ªã d·ªØ li·ªáu X_train, y_train...")
    y_train = df_train['SalePrice'] # Bi·∫øn m·ª•c ti√™u (ƒë√£ log-transform)
    X_train = df_train.drop(['SalePrice', 'Id'], axis=1) # ƒê·∫∑c tr∆∞ng

    print(f"   K√≠ch th∆∞·ªõc X_train: {X_train.shape}, y_train: {y_train.shape}")

    # 3. Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh
    print("üèãÔ∏è ƒêang hu·∫•n luy·ªán m√¥ h√¨nh XGBoost v·ªõi si√™u tham s·ªë t·ªët nh·∫•t...")
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train)
    print("   Hu·∫•n luy·ªán ho√†n t·∫•t.")

    # 4. L∆∞u m√¥ h√¨nh
    print(f"ƒêang l∆∞u m√¥ h√¨nh v√†o: {model_output_path}")
    # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
    os.makedirs(os.path.dirname(model_output_path), exist_ok=True)
    try:
        joblib.dump(model, model_output_path)
        print("M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng.")
    except Exception as e:
        print(f"L·ªói khi l∆∞u m√¥ h√¨nh: {e}")
        sys.exit(1)

    print("üèÅ Qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t.")
    return model # Tr·∫£ v·ªÅ m√¥ h√¨nh n·∫øu c·∫ßn d√πng ngay

# --- Ch·∫°y h√†m hu·∫•n luy·ªán khi script ƒë∆∞·ª£c th·ª±c thi ---
if __name__ == "__main__":
    trained_model = train_model(TRAIN_CLEAN_PATH, MODEL_OUTPUT_PATH, BEST_XGB_PARAMS)